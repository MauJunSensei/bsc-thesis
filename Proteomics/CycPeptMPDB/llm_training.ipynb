{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "657df731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at pingzhili/chemberta-v2-finetuned-uspto-50k-classification and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"pingzhili/chemberta-v2-finetuned-uspto-50k-classification\")\n",
    "model = AutoModel.from_pretrained(\"pingzhili/chemberta-v2-finetuned-uspto-50k-classification\")\n",
    "model.eval()\n",
    "\n",
    "def get_embedding(smiles):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(smiles, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs)\n",
    "        embedding = outputs.last_hidden_state.mean(dim=1)  # Mean pooling\n",
    "        return embedding.detach().numpy().flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fba8303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Drop columns with any empty rows\n",
    "data = pd.read_csv('CycPeptMPDB_Peptide_All.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c73c9f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of rows: 8466\n",
      "# of Columns before dropping: 247\n",
      "Number of rows after dropping duplicate molecules: 7991\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial number of rows: {len(data)}\")\n",
    "print(f'# of Columns before dropping: {data.shape[1]}')\n",
    "data = data.drop_duplicates(subset='Structurally_Unique_ID')\n",
    "print(f\"Number of rows after dropping duplicate molecules: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e3a6e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns after dropping those with missing values: 226\n",
      "Columns remaining: ['ID', 'Source', 'Year', 'Version', 'Original_Name_in_Source_Literature', 'Structurally_Unique_ID', 'SMILES', 'HELM', 'HELM_URL', 'Sequence', 'Sequence_LogP', 'Sequence_TPSA', 'Monomer_Length', 'Monomer_Length_in_Main_Chain', 'Molecule_Shape', 'Permeability', 'MaxEStateIndex', 'MinEStateIndex', 'MaxAbsEStateIndex', 'MinAbsEStateIndex', 'qed', 'MolWt', 'HeavyAtomMolWt', 'ExactMolWt', 'NumValenceElectrons', 'NumRadicalElectrons', 'MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'MinAbsPartialCharge', 'FpDensityMorgan1', 'FpDensityMorgan2', 'FpDensityMorgan3', 'BCUT2D_MWHI', 'BCUT2D_MWLOW', 'BCUT2D_CHGHI', 'BCUT2D_CHGLO', 'BCUT2D_LOGPHI', 'BCUT2D_LOGPLOW', 'BCUT2D_MRHI', 'BCUT2D_MRLOW', 'BalabanJ', 'BertzCT', 'Chi0', 'Chi0n', 'Chi0v', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3n', 'Chi3v', 'Chi4n', 'Chi4v', 'HallKierAlpha', 'Ipc', 'Kappa1', 'Kappa2', 'Kappa3', 'LabuteASA', 'PEOE_VSA1', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA12', 'PEOE_VSA13', 'PEOE_VSA14', 'PEOE_VSA2', 'PEOE_VSA3', 'PEOE_VSA4', 'PEOE_VSA5', 'PEOE_VSA6', 'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9', 'SMR_VSA1', 'SMR_VSA10', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6', 'SMR_VSA7', 'SMR_VSA8', 'SMR_VSA9', 'SlogP_VSA1', 'SlogP_VSA10', 'SlogP_VSA11', 'SlogP_VSA12', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4', 'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA7', 'SlogP_VSA8', 'SlogP_VSA9', 'TPSA', 'EState_VSA1', 'EState_VSA10', 'EState_VSA11', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4', 'EState_VSA5', 'EState_VSA6', 'EState_VSA7', 'EState_VSA8', 'EState_VSA9', 'VSA_EState1', 'VSA_EState10', 'VSA_EState2', 'VSA_EState3', 'VSA_EState4', 'VSA_EState5', 'VSA_EState6', 'VSA_EState7', 'VSA_EState8', 'VSA_EState9', 'FractionCSP3', 'HeavyAtomCount', 'NHOHCount', 'NOCount', 'NumAliphaticCarbocycles', 'NumAliphaticHeterocycles', 'NumAliphaticRings', 'NumAromaticCarbocycles', 'NumAromaticHeterocycles', 'NumAromaticRings', 'NumHAcceptors', 'NumHDonors', 'NumHeteroatoms', 'NumRotatableBonds', 'NumSaturatedCarbocycles', 'NumSaturatedHeterocycles', 'NumSaturatedRings', 'RingCount', 'MolLogP', 'MolMR', 'fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'fr_ArN', 'fr_Ar_COO', 'fr_Ar_N', 'fr_Ar_NH', 'fr_Ar_OH', 'fr_COO', 'fr_COO2', 'fr_C_O', 'fr_C_O_noCOO', 'fr_C_S', 'fr_HOCCN', 'fr_Imine', 'fr_NH0', 'fr_NH1', 'fr_NH2', 'fr_N_O', 'fr_Ndealkylation1', 'fr_Ndealkylation2', 'fr_Nhpyrrole', 'fr_SH', 'fr_aldehyde', 'fr_alkyl_carbamate', 'fr_alkyl_halide', 'fr_allylic_oxid', 'fr_amide', 'fr_amidine', 'fr_aniline', 'fr_aryl_methyl', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_bicyclic', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_ester', 'fr_ether', 'fr_furan', 'fr_guanido', 'fr_halogen', 'fr_hdrzine', 'fr_hdrzone', 'fr_imidazole', 'fr_imide', 'fr_isocyan', 'fr_isothiocyan', 'fr_ketone', 'fr_ketone_Topliss', 'fr_lactam', 'fr_lactone', 'fr_methoxy', 'fr_morpholine', 'fr_nitrile', 'fr_nitro', 'fr_nitro_arom', 'fr_nitro_arom_nonortho', 'fr_nitroso', 'fr_oxazole', 'fr_oxime', 'fr_para_hydroxylation', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperdine', 'fr_piperzine', 'fr_priamide', 'fr_prisulfonamd', 'fr_pyridine', 'fr_quatN', 'fr_sulfide', 'fr_sulfonamd', 'fr_sulfone', 'fr_term_acetylene', 'fr_tetrazole', 'fr_thiazole', 'fr_thiocyan', 'fr_thiophene', 'fr_unbrch_alkane', 'fr_urea', 'PC1', 'PC2']\n",
      "Number of rows after removing Permeability = -10: 7718\n"
     ]
    }
   ],
   "source": [
    "# Remove columns with any missing values\n",
    "data = data.dropna(axis=1)\n",
    "print(f\"Number of columns after dropping those with missing values: {data.shape[1]}\")\n",
    "print(f\"Columns remaining: {data.columns.tolist()}\")\n",
    "\n",
    "# Remove Permeabiltiy = -10\n",
    "data = data[data['Permeability'] != -10]\n",
    "print(f\"Number of rows after removing Permeability = -10: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32fd3425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 7718/7718 [02:40<00:00, 48.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "y = data['Permeability']\n",
    "\n",
    "def get_emb_thread(smiles):\n",
    "    return get_embedding(smiles)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    embeddings = list(tqdm(executor.map(get_emb_thread, data['SMILES']), total=len(data), desc=\"Generating embeddings\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4997685b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddings: 7718\n",
      "Size of y: 7718\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of embeddings: {len(embeddings)}\")\n",
    "print(f\"Size of y: {y.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "103db002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.4937\n",
      "RMSE: 0.6703\n",
      "R2: 0.2945\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Convert embeddings list to numpy array\n",
    "X = np.stack(embeddings)\n",
    "y_array = y.values\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_array, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R2: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a5c55d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_name = \"DeepChem/ChemBERTa-77M-MTR\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "def get_embedding_chemberta_77(smiles):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(smiles, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        outputs = model(**inputs)\n",
    "        token_embeddings = outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n",
    "        attention_mask = inputs['attention_mask']     # [batch_size, seq_len]\n",
    "\n",
    "        # Expand attention_mask to match token_embeddings dimensions\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "\n",
    "        # Perform mean pooling excluding padding tokens\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, dim=1)\n",
    "        sum_mask = input_mask_expanded.sum(dim=1).clamp(min=1e-9)\n",
    "        embedding = sum_embeddings / sum_mask\n",
    "\n",
    "        return embedding.detach().numpy().flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40392c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ChemBERTa-77M embeddings: 100%|██████████| 7718/7718 [00:22<00:00, 350.60it/s]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Multithreaded embedding generation for ChemBERTa-77M-MTR\n",
    "def get_emb_chemberta_77_thread(smiles):\n",
    "    return get_embedding_chemberta_77(smiles)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    embeddings_chemberta_77 = list(tqdm(executor.map(get_emb_chemberta_77_thread, data['SMILES']), total=len(data), desc=\"Generating ChemBERTa-77M embeddings\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53580f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of rows of Permeability: 7718\n",
      "Number of embeddings for ChemBERTa-77M: 7718\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial number of rows of Permeability: {len(y)}\")\n",
    "print(f\"Number of embeddings for ChemBERTa-77M: {len(embeddings_chemberta_77)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0287ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChemBERTa-77M RF MAE: 0.3924\n",
      "ChemBERTa-77M RF RMSE: 0.5321\n",
      "ChemBERTa-77M RF R2: 0.5554\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest model using ChemBERTa-77M embeddings\n",
    "X_chemberta_77 = np.stack(embeddings_chemberta_77)\n",
    "X_train_77, X_test_77, y_train_77, y_test_77 = train_test_split(X_chemberta_77, y_array, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_chemberta_77 = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "rf_chemberta_77.fit(X_train_77, y_train_77)\n",
    "\n",
    "y_pred_77 = rf_chemberta_77.predict(X_test_77)\n",
    "\n",
    "mae_77 = mean_absolute_error(y_test_77, y_pred_77)\n",
    "rmse_77 = np.sqrt(mean_squared_error(y_test_77, y_pred_77))\n",
    "r2_77 = r2_score(y_test_77, y_pred_77)\n",
    "\n",
    "print(f\"ChemBERTa-77M RF MAE: {mae_77:.4f}\")\n",
    "print(f\"ChemBERTa-77M RF RMSE: {rmse_77:.4f}\")\n",
    "print(f\"ChemBERTa-77M RF R2: {r2_77:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68cc46d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_77' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GradientBoostingRegressor\n\u001b[32m      3\u001b[39m gbm_77 = GradientBoostingRegressor(random_state=\u001b[32m42\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m gbm_77.fit(\u001b[43mX_train_77\u001b[49m, y_train_77)\n\u001b[32m      5\u001b[39m y_pred_gbm_77 = gbm_77.predict(X_test_77)\n\u001b[32m      7\u001b[39m mae_gbm_77 = mean_absolute_error(y_test_77, y_pred_gbm_77)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train_77' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbm_77 = GradientBoostingRegressor(random_state=42)\n",
    "gbm_77.fit(X_train_77, y_train_77)\n",
    "y_pred_gbm_77 = gbm_77.predict(X_test_77)\n",
    "\n",
    "mae_gbm_77 = mean_absolute_error(y_test_77, y_pred_gbm_77)\n",
    "rmse_gbm_77 = np.sqrt(mean_squared_error(y_test_77, y_pred_gbm_77))\n",
    "r2_gbm_77 = r2_score(y_test_77, y_pred_gbm_77)\n",
    "\n",
    "print(f\"ChemBERTa-77M Gradient Boosting MAE: {mae_gbm_77:.4f}\")\n",
    "print(f\"ChemBERTa-77M Gradient Boosting RMSE: {rmse_gbm_77:.4f}\")\n",
    "print(f\"ChemBERTa-77M Gradient Boosting R2: {r2_gbm_77:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
